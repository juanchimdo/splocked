{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelining and Deploying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a smaller dataset to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_spoiler</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>review_text</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>10</td>\n",
       "      <td>10 February 2006</td>\n",
       "      <td>A classic piece of unforgettable film-making.</td>\n",
       "      <td>In its Oscar year, Shawshank Redemption (writt...</td>\n",
       "      <td>ur1898687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>10</td>\n",
       "      <td>6 September 2000</td>\n",
       "      <td>Simply amazing. The best film of the 90's.</td>\n",
       "      <td>The Shawshank Redemption is without a doubt on...</td>\n",
       "      <td>ur0842118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>8</td>\n",
       "      <td>3 August 2001</td>\n",
       "      <td>The best story ever told on film</td>\n",
       "      <td>I believe that this film is the best story eve...</td>\n",
       "      <td>ur1285640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>10</td>\n",
       "      <td>1 September 2002</td>\n",
       "      <td>Busy dying or busy living?</td>\n",
       "      <td>**Yes, there are SPOILERS here**This film has ...</td>\n",
       "      <td>ur1003471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>8</td>\n",
       "      <td>20 May 2004</td>\n",
       "      <td>Great story, wondrously told and acted</td>\n",
       "      <td>At the heart of this extraordinary movie is a ...</td>\n",
       "      <td>ur0226855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_spoiler   movie_id  rating       review_date  \\\n",
       "0        True  tt0111161      10  10 February 2006   \n",
       "1        True  tt0111161      10  6 September 2000   \n",
       "2        True  tt0111161       8     3 August 2001   \n",
       "3        True  tt0111161      10  1 September 2002   \n",
       "4        True  tt0111161       8       20 May 2004   \n",
       "\n",
       "                                  review_summary  \\\n",
       "0  A classic piece of unforgettable film-making.   \n",
       "1     Simply amazing. The best film of the 90's.   \n",
       "2               The best story ever told on film   \n",
       "3                     Busy dying or busy living?   \n",
       "4         Great story, wondrously told and acted   \n",
       "\n",
       "                                         review_text    user_id  \n",
       "0  In its Oscar year, Shawshank Redemption (writt...  ur1898687  \n",
       "1  The Shawshank Redemption is without a doubt on...  ur0842118  \n",
       "2  I believe that this film is the best story eve...  ur1285640  \n",
       "3  **Yes, there are SPOILERS here**This film has ...  ur1003471  \n",
       "4  At the heart of this extraordinary movie is a ...  ur0226855  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('./../../raw_data/IMDB_reviews.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(573913, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     500\n",
       "False    500\n",
       "Name: is_spoiler, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df = df[df['is_spoiler']==True].iloc[:500]\n",
    "f_df = df[df['is_spoiler']==False].iloc[:500]\n",
    "small_df = pd.concat([t_df, f_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_spoiler</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>A classic piece of unforgettable film-making. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>Simply amazing. The best film of the 90's. The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>The best story ever told on film I believe tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>Busy dying or busy living? **Yes, there are SP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>Great story, wondrously told and acted At the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_spoiler                                             review\n",
       "0        True  A classic piece of unforgettable film-making. ...\n",
       "1        True  Simply amazing. The best film of the 90's. The...\n",
       "2        True  The best story ever told on film I believe tha...\n",
       "3        True  Busy dying or busy living? **Yes, there are SP...\n",
       "4        True  Great story, wondrously told and acted At the ..."
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_df['review'] = small_df['review_summary'] + ' ' + small_df['review_text']\n",
    "small_df = small_df[['is_spoiler', 'review']]\n",
    "small_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(small_df['review'], small_df['is_spoiler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369    You must to see this film A story of friendshi...\n",
       "424    Awesome This is simply one of the best films e...\n",
       "934    hope....is greatest thing i watched this movie...\n",
       "422    An amazing movie everyone will love So, I firs...\n",
       "316    the most downtrodden film Oscar 's story? The ...\n",
       "755    Best movie ever One of the best movies that i ...\n",
       "739    - Some things Are Best left Unsaid - When you ...\n",
       "681    A true story of friendship and hard times Shaw...\n",
       "826    Cinematic masterpiece Have seen this film a co...\n",
       "813    Time Flies One interesting thing about this mo...\n",
       "969    Plainly Superb! Let me start out by saying tha...\n",
       "741    an alright movie to watch It is not uncommon t...\n",
       "960    A Truly Amazing Experience This title has to b...\n",
       "82     good reviews of best movie of all time The Sha...\n",
       "566    prison escape This film manages to redeem Holl...\n",
       "444    The best movie ever made. The Shawshank Redemp...\n",
       "554    I didn't think films could be this good.... Th...\n",
       "68     Why the ending is so moving I myself, like mos...\n",
       "39     Was I watching another movie? The Shawshank Re...\n",
       "663    Sure it's good, but no. 2 of all time??? Sure ...\n",
       "98     Classic Movie One of the classic movie ever ma...\n",
       "597    Magical film I remember when i first saw this ...\n",
       "559    A genre picture, but a satisfying one... Tim R...\n",
       "34     Best film I have ever seen I don't write film ...\n",
       "515    One of the best movies ever made? Probably yes...\n",
       "125    How could one movie be so terrible ***SPOILERS...\n",
       "561    Best movie of all time! The first time I ever ...\n",
       "180    amazing one of the best movies i have ever wat...\n",
       "133    Do not lose hope in desperate moments. There a...\n",
       "793    Inspirational Inspirational.Get busy living or...\n",
       "                             ...                        \n",
       "493    Awesome Movie An excellent thriller movie to w...\n",
       "821    Hope is a good thing, maybe the best of things...\n",
       "513    The closest thing to poetic perfection Hollywo...\n",
       "838    Great This was one of the greatest movies i ha...\n",
       "754    Best film ever If you have not seen this film ...\n",
       "542    The UNIVERSALITY of Shawshank:. Andy Dufresne ...\n",
       "302    Shawshank This movie is a very good look into ...\n",
       "151    Is it possible to doubt that this is a masterp...\n",
       "127    Definitely on my top 1000 list I hadn't seen t...\n",
       "366    Fantastic and brilliant This movie is just ama...\n",
       "940    A Cinematic Masterpiece!!! The Shawshank Redem...\n",
       "188    best movie every seen Why do I want to write t...\n",
       "637    best movie ever this film is an award winning ...\n",
       "752    Best Movie Of The Era To be brief, as a man wh...\n",
       "893    Honestly, one of the best films I've ever seen...\n",
       "219    Opinion of an amateur. I think that in this fi...\n",
       "872    Just Great This movie really displays how horr...\n",
       "942    They sure don't make em like this anymore Not ...\n",
       "802    One of the brightest gems from the Hollywood t...\n",
       "580    Hope......Don't loose it at any cost The 'Shaw...\n",
       "455    Intriguing, interesting , keeps you involved ....\n",
       "498    Beautyfull Movie The story begins with the tri...\n",
       "798    Does this film deserve it's praise? I know lot...\n",
       "169    favorite movie! One of my all time favorites. ...\n",
       "190    This is legendary movie I have seen this movie...\n",
       "87     The best ever! When I saw that this movie was ...\n",
       "516    Over Rated There is no denying that this is a ...\n",
       "274    Great Movie The Shawshank Redemption ReviewThe...\n",
       "618    awesome movie awesome movie...the story is hig...\n",
       "148    The Shawshank Redemption is written and direct...\n",
       "Name: review, Length: 750, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean reviews text\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "import unidecode\n",
    "\n",
    "\n",
    "def clean (text):\n",
    "    \n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, ' ') # Remove Punctuation\n",
    "        \n",
    "    lowercased = text.lower() # Lower Case\n",
    "    \n",
    "    unaccented_string = unidecode.unidecode(lowercased) # remove accents\n",
    "    \n",
    "    tokenized = word_tokenize(unaccented_string) # Tokenize\n",
    "    \n",
    "    words_only = [word for word in tokenized if word.isalpha()] # Remove numbers\n",
    "    \n",
    "    stop_words = set(stopwords.words('portuguese')) # Make stopword list\n",
    "    \n",
    "    without_stopwords = [word for word in words_only if not word in stop_words] # Remove Stop Words\n",
    "    \n",
    "    return \" \".join(without_stopwords)\n",
    "\n",
    "df['clean_text'] = df['title_comment'].apply(clean)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to list of list of words\n",
    "def convert_sentences(X):\n",
    "    return [sentence.split(' ') for sentence in X]\n",
    "\n",
    "X_train = convert_sentences(X_train)\n",
    "X_test = convert_sentences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['You',\n",
       " 'must',\n",
       " 'to',\n",
       " 'see',\n",
       " 'this',\n",
       " 'film',\n",
       " 'A',\n",
       " 'story',\n",
       " 'of',\n",
       " 'friendship',\n",
       " 'and',\n",
       " 'endurance',\n",
       " 'set',\n",
       " 'in',\n",
       " 'the',\n",
       " 'reality',\n",
       " 'of',\n",
       " 'prison',\n",
       " 'life,',\n",
       " 'The',\n",
       " 'Shawshank',\n",
       " 'Redemption',\n",
       " 'is',\n",
       " 'best',\n",
       " 'known',\n",
       " 'as',\n",
       " 'an',\n",
       " 'Oscar-nominated',\n",
       " 'film.',\n",
       " 'However,',\n",
       " 'this',\n",
       " 'theatre',\n",
       " 'production',\n",
       " 'is',\n",
       " 'based',\n",
       " 'instead',\n",
       " 'on',\n",
       " 'the',\n",
       " 'original',\n",
       " 'novella',\n",
       " 'written',\n",
       " 'by',\n",
       " 'Stephen',\n",
       " 'King',\n",
       " 'relatively',\n",
       " 'early',\n",
       " 'in',\n",
       " 'his',\n",
       " 'career.The',\n",
       " 'direction',\n",
       " 'in',\n",
       " 'this',\n",
       " 'piece',\n",
       " 'is',\n",
       " 'stylised,',\n",
       " 'with',\n",
       " 'a',\n",
       " 'deliberate',\n",
       " 'slow',\n",
       " 'rhythm',\n",
       " 'and',\n",
       " 'pace,',\n",
       " 'particularly',\n",
       " 'in',\n",
       " 'the',\n",
       " 'first',\n",
       " 'act,',\n",
       " 'greatly',\n",
       " 'reducing',\n",
       " 'any',\n",
       " 'sense',\n",
       " 'of',\n",
       " 'menace',\n",
       " 'that',\n",
       " 'you',\n",
       " 'would',\n",
       " 'expect',\n",
       " 'from',\n",
       " 'this',\n",
       " 'so-called',\n",
       " 'tough',\n",
       " 'prison.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'almost',\n",
       " 'Brechtian',\n",
       " 'in',\n",
       " 'style.',\n",
       " 'This',\n",
       " 'becomes',\n",
       " 'frustrating',\n",
       " 'as',\n",
       " 'it',\n",
       " 'takes',\n",
       " 'much',\n",
       " 'of',\n",
       " 'the',\n",
       " 'emotion',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'production;',\n",
       " 'a',\n",
       " 'vital',\n",
       " 'piece',\n",
       " 'of',\n",
       " 'the',\n",
       " 'human',\n",
       " 'connection',\n",
       " 'that',\n",
       " 'then',\n",
       " 'means',\n",
       " 'the',\n",
       " 'audience',\n",
       " 'is',\n",
       " 'less',\n",
       " 'invested',\n",
       " 'in',\n",
       " 'the',\n",
       " 'outcome',\n",
       " 'of',\n",
       " 'the',\n",
       " 'possibly',\n",
       " 'innocent',\n",
       " 'Andy',\n",
       " 'Dufresne',\n",
       " 'and',\n",
       " 'the',\n",
       " 'lovable',\n",
       " 'rouge',\n",
       " 'Red.',\n",
       " 'This',\n",
       " 'underplaying',\n",
       " 'of',\n",
       " 'emotion',\n",
       " 'results',\n",
       " 'in',\n",
       " 'a',\n",
       " 'restrained',\n",
       " 'and',\n",
       " 'difficult',\n",
       " 'to',\n",
       " 'engage',\n",
       " 'with',\n",
       " 'character',\n",
       " 'in',\n",
       " 'Dufresne,',\n",
       " 'played',\n",
       " 'by',\n",
       " 'Ian',\n",
       " 'Kelsey.',\n",
       " 'There',\n",
       " 'are',\n",
       " 'moments',\n",
       " 'of',\n",
       " 'anguish',\n",
       " 'from',\n",
       " 'Kelsey,',\n",
       " 'but',\n",
       " 'with',\n",
       " 'the',\n",
       " 'direction',\n",
       " 'holding',\n",
       " 'such',\n",
       " 'a',\n",
       " 'tight',\n",
       " 'reign',\n",
       " 'on',\n",
       " 'the',\n",
       " 'characters,',\n",
       " 'the',\n",
       " 'moments',\n",
       " 'are',\n",
       " 'too',\n",
       " 'far',\n",
       " 'and',\n",
       " 'between.',\n",
       " 'Patrick',\n",
       " \"Robinson's\",\n",
       " 'Red',\n",
       " 'fares',\n",
       " 'a',\n",
       " 'little',\n",
       " 'better',\n",
       " 'as',\n",
       " 'he',\n",
       " 'addresses',\n",
       " 'the',\n",
       " 'audience',\n",
       " 'with',\n",
       " 'a',\n",
       " 'charming',\n",
       " 'older',\n",
       " 'storytelling',\n",
       " 'voice,',\n",
       " 'but',\n",
       " 'is',\n",
       " 'still',\n",
       " 'not',\n",
       " 'given',\n",
       " 'enough',\n",
       " 'freedom',\n",
       " 'to',\n",
       " 'truly',\n",
       " 'embrace',\n",
       " \"Red's\",\n",
       " 'charisma.',\n",
       " 'When',\n",
       " 'using',\n",
       " 'this',\n",
       " 'deliberate',\n",
       " 'stylised',\n",
       " 'direction,',\n",
       " 'the',\n",
       " 'impact',\n",
       " 'on',\n",
       " 'the',\n",
       " 'reality',\n",
       " 'of',\n",
       " 'the',\n",
       " 'stage',\n",
       " 'fighting',\n",
       " 'also',\n",
       " 'showed,',\n",
       " 'again',\n",
       " 'detracting',\n",
       " 'from',\n",
       " 'the',\n",
       " 'idea',\n",
       " 'of',\n",
       " 'brutality.The',\n",
       " 'second',\n",
       " 'half',\n",
       " 'picks',\n",
       " 'up',\n",
       " 'the',\n",
       " 'pace',\n",
       " 'slightly',\n",
       " 'and',\n",
       " 'the',\n",
       " 'play',\n",
       " 'overall',\n",
       " 'is',\n",
       " 'watchable',\n",
       " 'with',\n",
       " 'good',\n",
       " 'performances',\n",
       " 'all',\n",
       " 'round',\n",
       " 'from',\n",
       " 'the',\n",
       " 'cast.',\n",
       " 'However,',\n",
       " 'without',\n",
       " 'the',\n",
       " 'rawness',\n",
       " 'derived',\n",
       " 'from',\n",
       " 'emotional',\n",
       " 'context,',\n",
       " 'the',\n",
       " 'prison',\n",
       " 'life',\n",
       " 'never',\n",
       " 'feels',\n",
       " 'as',\n",
       " 'if',\n",
       " 'it',\n",
       " 'is',\n",
       " 'unbearable',\n",
       " 'to',\n",
       " 'be',\n",
       " 'in',\n",
       " 'or',\n",
       " 'watch,',\n",
       " 'meaning',\n",
       " 'the',\n",
       " 'power',\n",
       " 'of',\n",
       " 'the',\n",
       " 'ending',\n",
       " 'is',\n",
       " 'lessened.By',\n",
       " 'Isabella',\n",
       " 'Fraser']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(X):\n",
    "    # LET IT AS IT IS\n",
    "    return X\n",
    "\n",
    "X_clean_train = data_cleaning(X_train)\n",
    "X_clean_test = data_cleaning(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = {}\n",
    "iter_ = 1\n",
    "for sentence in X_clean_train:\n",
    "    for word in sentence:\n",
    "        if word in word_to_id:\n",
    "            continue\n",
    "        word_to_id[word] = iter_\n",
    "        iter_ += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18247 different words in the train sentences\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {len(word_to_id)} different words in the train sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_word = {v:k for k, v in word_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentences, word_to_id):\n",
    "    return [[word_to_id[_] for _ in s if _ in word_to_id] for s in sentences]\n",
    "\n",
    "X_token_train = tokenize(X_clean_train, word_to_id)\n",
    "X_token_test = tokenize(X_clean_test, word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train_pad = pad_sequences(X_token_train, dtype='float32', padding='post')\n",
    "X_test_pad = pad_sequences(X_token_test, dtype='float32', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 998)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_train = np.array([1 if x else 0 for x in y_train])\n",
    "y_test = np.array([1 if x else 0 for x in y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers \n",
    "\n",
    "def init_model(vocab_size):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(input_dim=vocab_size+1, output_dim=30, mask_zero=True))\n",
    "    model.add(layers.LSTM(10))\n",
    "    model.add(layers.Dense(5))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 [==============================] - 12s 680ms/step - loss: 0.6932 - accuracy: 0.5143 - val_loss: 0.6934 - val_accuracy: 0.5200\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 10s 584ms/step - loss: 0.6792 - accuracy: 0.7638 - val_loss: 0.6950 - val_accuracy: 0.4889\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 10s 586ms/step - loss: 0.6151 - accuracy: 0.8229 - val_loss: 0.7247 - val_accuracy: 0.5422\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 10s 591ms/step - loss: 0.4847 - accuracy: 0.8495 - val_loss: 0.6829 - val_accuracy: 0.5822\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 10s 602ms/step - loss: 0.3727 - accuracy: 0.8895 - val_loss: 0.7567 - val_accuracy: 0.5467\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 10s 602ms/step - loss: 0.2596 - accuracy: 0.9371 - val_loss: 0.7851 - val_accuracy: 0.5689\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 10s 610ms/step - loss: 0.1881 - accuracy: 0.9581 - val_loss: 0.8643 - val_accuracy: 0.5378\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 11s 621ms/step - loss: 0.1474 - accuracy: 0.9638 - val_loss: 0.9258 - val_accuracy: 0.5600\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 11s 659ms/step - loss: 0.1084 - accuracy: 0.9733 - val_loss: 0.9154 - val_accuracy: 0.5956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x125be0990>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############\n",
    "### Answer ###\n",
    "##############\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = init_model(len(word_to_id))\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train_pad, y_train, \n",
    "          epochs=10, \n",
    "          batch_size=32,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 30)          547440    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 10)                1640      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 549,141\n",
      "Trainable params: 549,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_review = \"I loved the movie, it was fantastic and thrilling, you should really see it. I recommend it\"\n",
    "# Convert Sentences\n",
    "inpute_review = convert_sentences(input_review)\n",
    "# Tokenize\n",
    "input_review = tokenize(input_review, word_to_id)\n",
    "# Pad\n",
    "input_review = pad_sequences(input_review, dtype='float32', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your input has a 48.3% chance of being a spoiler\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(input_review).mean()\n",
    "print(f'Your input has a {round(res*100, 1)}% chance of being a spoiler')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
